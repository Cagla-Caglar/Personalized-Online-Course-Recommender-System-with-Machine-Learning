{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork817-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Course Rating Prediction using Neural Networks**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **60** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous labs, we have crafted several types of user and item feature vectors.  For example, given a user `i`, we may build its profile feature vector and course rating feature vector, and given an item `j`, we may create its genre vector and user enrollment vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "With these explicit features vectors, we can perform machine learning tasks such as calculating the similarities among users or items, finding nearest neighbors, and using dot-product to estimate a rating value. \n",
    "\n",
    "The main advantage of using these explicit features is they are highly interpretable and yield very good performance as well. The main disadvantage is we need to spend quite some effort to build and store them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_4/images/explicit_user_item_features.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it possible to predict a rating without building explicit feature vectors beforehand?  \n",
    "\n",
    "Yes, as you may recall, the Non-negative Matrix Factorization decomposes the user-item interaction matrix into user matrix and item matrix, which contain the latent features of users and items and you can simply dot-product them to get an estimated rating.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_4/images/nmf.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to NMF, neural networks can also be used to extract the latent user and item features  In fact,  neural networks are very good at learning patterns from data and are widely used to extract latent features.  When training neural networks, it gradually captures and stores the features within its hidden layers as weight matrices and can be extracted to represent the original data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will be training neural networks to predict course ratings while simultaneously extracting users' and items' latent features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `tensorflow` to train neural networks to extract the user and item latent features from the hidden's layers  \n",
    "* Predict course ratings with trained neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and setup lab environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install tensorflow if not installed before in your Python environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m151.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.13.0 keras-3.9.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.1 protobuf-5.29.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and import required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 16:24:49.160257: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 16:24:49.161485: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-10 16:24:49.166439: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-10 16:24:49.178538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741623889.200126    3147 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741623889.206125    3147 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 16:24:49.231501: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also set a random state\n",
    "rs = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and processing rating dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889878</td>\n",
       "      <td>CC0101EN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1342067</td>\n",
       "      <td>CL0101EN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990814</td>\n",
       "      <td>ML0120ENv3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380098</td>\n",
       "      <td>BD0211EN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>779563</td>\n",
       "      <td>DS0101EN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user        item  rating\n",
       "0  1889878    CC0101EN       5\n",
       "1  1342067    CL0101EN       3\n",
       "2  1990814  ML0120ENv3       5\n",
       "3   380098    BD0211EN       5\n",
       "4   779563    DS0101EN       3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-ML0321EN-Coursera/labs/v2/module_3/ratings.csv\"\n",
    "rating_df = pd.read_csv(rating_url)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same rating dataset we have been using in previous lab, which contains the three main columns: `user`, `item`, and `rating`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's figure out how many unique users and items, their total numbers will determine the sizes of one-hot encoding vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total `33901` of users and `126` items\n"
     ]
    }
   ],
   "source": [
    "num_users = len(rating_df['user'].unique())\n",
    "num_items = len(rating_df['item'].unique())\n",
    "print(f\"There are total `{num_users}` of users and `{num_items}` items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means our each user can be represented as a `33901 x 1` one-hot vector and each item can be represented as `126 x 1` one-hot vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to create a neural network structure that can take the user and item one-hot vectors as inputs and outputs a rating estimation or the probability of interaction.\n",
    "\n",
    "While training and updating the weights in the neural network, its hidden layers should be able to capture the pattern or features for each user and item. Based on this idea, we can design a simple neural network architecture like the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_4/images/embedding_feature_vector.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network inputs are two one-hot encoding vectors, the blue one is for the user and the green one is for the item. Then on top of them, we added two embedding layers. Here embedding means embedding the one-hot encoding vector into a latent feature space. The embedding layer is a fully-connected layer that outputs the embedding feature vectors. For example, the user embedding layer takes `33901 x 1` one-hot vector as input and outputs a `16 x 1` embedding vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding layer outputs two embedding vectors, which are similar to Non-negative matrix factorization. Then we could simply dot the product the user and item embedding vector to output a rating estimation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing the recommender neural network using tensorflow \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network architecture could be defined and implemented as a sub-class inheriting the `tensorflow.keras.Model` super class, let's call it `RecommenderNet()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderNet(keras.Model):\n",
    "    \"\"\"\n",
    "        Neural network model for recommendation.\n",
    "\n",
    "        This model learns embeddings for users and items, and computes the dot product\n",
    "        of the user and item embeddings to predict ratings or preferences.\n",
    "\n",
    "        Attributes:\n",
    "        - num_users (int): Number of users.\n",
    "        - num_items (int): Number of items.\n",
    "        - embedding_size (int): Size of embedding vectors for users and items.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_users, num_items, embedding_size=16, **kwargs):\n",
    "        \"\"\"\n",
    "            Constructor.\n",
    "\n",
    "            Args:\n",
    "            - num_users (int): Number of users.\n",
    "            - num_items (int): Number of items.\n",
    "            - embedding_size (int): Size of embedding vectors for users and items.\n",
    "         \"\"\"\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # Define a user_embedding vector\n",
    "        # Input dimension is the num_users\n",
    "        # Output dimension is the embedding size\n",
    "        # A name for the layer, which helps in identifying the layer within the model.\n",
    "\n",
    "        self.user_embedding_layer = layers.Embedding(\n",
    "            input_dim=num_users,\n",
    "            output_dim=embedding_size,\n",
    "            name='user_embedding_layer',\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        # Define a user bias layer\n",
    "        # Bias is applied per user, hence output_dim is set to 1.\n",
    "        self.user_bias = layers.Embedding(\n",
    "            input_dim=num_users,\n",
    "            output_dim=1,\n",
    "            name=\"user_bias\")\n",
    "\n",
    "        # Define an item_embedding vector\n",
    "        # Input dimension is the num_items\n",
    "        # Output dimension is the embedding size\n",
    "        self.item_embedding_layer = layers.Embedding(\n",
    "            input_dim=num_items,\n",
    "            output_dim=embedding_size,\n",
    "            name='item_embedding_layer',\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        # Define an item bias layer\n",
    "        # Bias is applied per item, hence output_dim is set to 1.\n",
    "        self.item_bias = layers.Embedding(\n",
    "            input_dim=num_items,\n",
    "            output_dim=1,\n",
    "            name=\"item_bias\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "            Method called during model fitting.\n",
    "\n",
    "            Args:\n",
    "            - inputs (tf.Tensor): Input tensor containing user and item one-hot vectors.\n",
    "\n",
    "            Returns:\n",
    "            - tf.Tensor: Output tensor containing predictions.\n",
    "        \"\"\"\n",
    "        # Compute the user embedding vector\n",
    "        user_vector = self.user_embedding_layer(inputs[:, 0])\n",
    "        # Compute the user bias\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        # Compute the item embedding vector\n",
    "        item_vector = self.item_embedding_layer(inputs[:, 1])\n",
    "        # Compute the item bias\n",
    "        item_bias = self.item_bias(inputs[:, 1])\n",
    "         # Compute dot product of user and item embeddings\n",
    "        dot_user_item = tf.tensordot(user_vector, item_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_item + user_bias + item_bias\n",
    "        # Apply ReLU activation function\n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: Train and evaluate the RecommenderNet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to train and evaluate the defined `RecommenderNet()`. First, we need to process the original rating dataset a little bit by converting the actual user ids and item ids into integer indices for `tensorflow` to creating the one-hot encoding vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(raw_data):\n",
    "    \"\"\"\n",
    "        Preprocesses the raw dataset by encoding user and item IDs to indices.\n",
    "\n",
    "        Args:\n",
    "        - raw_data (DataFrame): Raw dataset containing user, item, and rating information.\n",
    "\n",
    "        Returns:\n",
    "        - encoded_data (DataFrame): Processed dataset with user and item IDs encoded as indices.\n",
    "        - user_idx2id_dict (dict): Dictionary mapping user indices to original user IDs.\n",
    "        - course_idx2id_dict (dict): Dictionary mapping item indices to original item IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    encoded_data = raw_data.copy()\n",
    "\n",
    "    # Mapping user ids to indices\n",
    "    user_list = encoded_data[\"user\"].unique().tolist()\n",
    "    user_id2idx_dict = {x: i for i, x in enumerate(user_list)}\n",
    "    user_idx2id_dict = {i: x for i, x in enumerate(user_list)}\n",
    "\n",
    "    # Mapping course ids to indices\n",
    "    course_list = encoded_data[\"item\"].unique().tolist()\n",
    "    course_id2idx_dict = {x: i for i, x in enumerate(course_list)}\n",
    "    course_idx2id_dict = {i: x for i, x in enumerate(course_list)}\n",
    "\n",
    "    # Convert original user ids to idx\n",
    "    encoded_data[\"user\"] = encoded_data[\"user\"].map(user_id2idx_dict)\n",
    "    # Convert original course ids to idx\n",
    "    encoded_data[\"item\"] = encoded_data[\"item\"].map(course_id2idx_dict)\n",
    "    # Convert rating to int\n",
    "    encoded_data[\"rating\"] = encoded_data[\"rating\"].values.astype(\"int\")\n",
    "\n",
    "    return encoded_data, user_idx2id_dict, course_idx2id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the raw dataset using the process_dataset function\n",
    "# The function returns three values: encoded_data, user_idx2id_dict, and course_idx2id_dict\n",
    "# encoded_data: Processed dataset with user and item IDs encoded as indices\n",
    "# user_idx2id_dict: Dictionary mapping user indices to original user IDs\n",
    "# course_idx2id_dict: Dictionary mapping item indices to original item IDs\n",
    "encoded_data, user_idx2id_dict, course_idx2id_dict = process_dataset(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     0     0       5\n",
       "1     1     1       3\n",
       "2     2     2       5\n",
       "3     3     3       5\n",
       "4     4     4       3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can split the encoded dataset into training and testing datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_datasets(dataset, scale=True):\n",
    "    \"\"\"\n",
    "        Splits the dataset into training, validation, and testing sets.\n",
    "\n",
    "        Args:\n",
    "        - dataset (DataFrame): Dataset containing user, item, and rating information.\n",
    "        - scale (bool): Indicates whether to scale the ratings between 0 and 1. Default is True.\n",
    "\n",
    "       Returns:\n",
    "        - x_train (array): Features for training set.\n",
    "        - x_val (array): Features for validation set.\n",
    "        - x_test (array): Features for testing set.\n",
    "        - y_train (array): Labels for training set.\n",
    "        - y_val (array): Labels for validation set.\n",
    "        - y_test (array): Labels for testing set.\n",
    "    \"\"\"\n",
    "\n",
    "    min_rating = min(dataset[\"rating\"])\n",
    "    max_rating = max(dataset[\"rating\"]) \n",
    "\n",
    "    dataset = dataset.sample(frac=1, random_state=42)\n",
    "    x = dataset[[\"user\", \"item\"]].values\n",
    "    if scale:\n",
    "        # Scale the ratings between 0 and 1 if scale=True\n",
    "        y = dataset[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "    else:\n",
    "        # Otherwise, use raw ratings\n",
    "        y = dataset[\"rating\"].values\n",
    "\n",
    "    # Assuming training on 80% of the data and testing on 10% of the data\n",
    "    train_indices = int(0.8 * dataset.shape[0])\n",
    "    test_indices = int(0.9 * dataset.shape[0])\n",
    "    # Assigning subsets of features and labels for each set\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = (\n",
    "        x[:train_indices],\n",
    "        x[train_indices:test_indices],\n",
    "        x[test_indices:],\n",
    "        y[:train_indices],\n",
    "        y[train_indices:test_indices],\n",
    "        y[test_indices:],\n",
    "    )\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = generate_train_test_datasets(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the training input data, it is simply just a list of user indices and item indices, which is a dense format of one-hot encoding vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8376,  7659, 10717, ...,  3409, 28761,  4973])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_indices = x_train[:, 0]\n",
    "user_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 29,  3, ..., 18, 19, 17])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_indices = x_train[:, 1]\n",
    "item_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training output labels are a list of 0s and 1s indicating if the user has completed a course or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can choose a small embedding vector size to be 16 and create a `RecommenderNet()` model to be trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 16\n",
    "model = RecommenderNet(num_users, num_items, embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO: Train the RecommenderNet() model_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 16:25:30.284189: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 25ms/step - loss: 0.2319 - root_mean_squared_error: 0.4791 - val_loss: 0.1792 - val_root_mean_squared_error: 0.4226\n",
      "Epoch 2/10\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 25ms/step - loss: 0.1753 - root_mean_squared_error: 0.4179 - val_loss: 0.1779 - val_root_mean_squared_error: 0.4208\n",
      "Epoch 3/10\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 24ms/step - loss: 0.1593 - root_mean_squared_error: 0.3980 - val_loss: 0.1798 - val_root_mean_squared_error: 0.4227\n",
      "Epoch 4/10\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 25ms/step - loss: 0.1550 - root_mean_squared_error: 0.3921 - val_loss: 0.1831 - val_root_mean_squared_error: 0.4261\n",
      "Epoch 5/10\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 25ms/step - loss: 0.1517 - root_mean_squared_error: 0.3874 - val_loss: 0.1867 - val_root_mean_squared_error: 0.4299\n",
      "Epoch 6/10\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 25ms/step - loss: 0.1505 - root_mean_squared_error: 0.3854 - val_loss: 0.1910 - val_root_mean_squared_error: 0.4346\n",
      "Epoch 7/10\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 25ms/step - loss: 0.1505 - root_mean_squared_error: 0.3850 - val_loss: 0.1939 - val_root_mean_squared_error: 0.4376\n",
      "Epoch 8/10\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 24ms/step - loss: 0.1493 - root_mean_squared_error: 0.3832 - val_loss: 0.1965 - val_root_mean_squared_error: 0.4403\n",
      "Epoch 9/10\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 24ms/step - loss: 0.1496 - root_mean_squared_error: 0.3833 - val_loss: 0.1986 - val_root_mean_squared_error: 0.4425\n",
      "Epoch 10/10\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 24ms/step - loss: 0.1494 - root_mean_squared_error: 0.3828 - val_loss: 0.2010 - val_root_mean_squared_error: 0.4450\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save model weights\n",
    "model.save_weights(\"recommender_net_weights.weights.h5\")\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Hints</summary>\n",
    "    \n",
    "When you are fitting a model, dont forget to specify the parameters: `x=x_train, y=y_train`, as well as `batch_size=64`, number of `epochs=10` and of course `validation_data=(x_val, y_val)` you can also define `verbose = 1` which will show you an animated progress for the training progress for each epoch.\n",
    "    \n",
    "* You can set  `history = model.fit()` which will give you a \"loss\" dataframe which will be very useful for ploting the train and validation loss. To plot it, use plt.plot() with `history.history[\"loss\"]` as its parameter for train loss and `history.history[\"val_loss\"]` for validation loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO:_ Evaluate the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (2.0.2)\n",
      "\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Test RMSE: 0.4411\n"
     ]
    }
   ],
   "source": [
    "### - call model.evaluate() to evaluate the model\n",
    "!pip install scikit-learn\n",
    "!pip install numpy\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Hints</summary>\n",
    "    \n",
    "Use `x_test, y_test` as parameters for `model.evaluate()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the user and item embedding vectors as latent feature vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have trained the `RecommenderNet()` model and it can predict the ratings with relatively small RMSE. \n",
    "\n",
    "If we print the trained model then we can see its layers and their parameters/weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"recommender_net\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"recommender_net\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ user_embedding_layer            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">542,416</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ user_bias (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,901</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ item_embedding_layer            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,016</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ item_bias (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ user_embedding_layer            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │       \u001b[38;5;34m542,416\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)                     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ user_bias (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m33,901\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ item_embedding_layer            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,016\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)                     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ item_bias (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m126\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,735,379</span> (6.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,735,379\u001b[0m (6.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">578,459</span> (2.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m578,459\u001b[0m (2.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,156,920</span> (4.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,156,920\u001b[0m (4.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `RecommenderNet`, the `user_embedding_layer` and `item_embedding_layer` layers contain the trained weights. Essentially, they are the latent user and item features learned by `RecommenderNet` and will be used to predict the interaction. As such, while training the neural network to predict rating, the embedding layers are simultaneously trained to extract the embedding user and item features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily get the actual weights using `model.get_layer().get_weights()` methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User features shape: (33901, 16)\n"
     ]
    }
   ],
   "source": [
    "# User features\n",
    "user_latent_features = model.get_layer('user_embedding_layer').get_weights()[0]\n",
    "print(f\"User features shape: {user_latent_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2294598 ,  0.02699741,  0.07465818, -0.05641278, -0.02073733,\n",
       "       -0.0264949 , -0.05410108,  0.03834464, -0.08473603,  0.00778265,\n",
       "       -0.16617298, -0.06563926, -0.11998791,  0.11615825, -0.00207008,\n",
       "       -0.03399637], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_latent_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item features shape: (126, 16)\n"
     ]
    }
   ],
   "source": [
    "item_latent_features = model.get_layer('item_embedding_layer').get_weights()[0]\n",
    "print(f\"Item features shape: {item_latent_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00692923,  0.0134759 ,  0.02287174,  0.00309723, -0.00563877,\n",
       "        0.00596443,  0.00866522,  0.00340577, -0.02651206, -0.0142477 ,\n",
       "       -0.01712408,  0.0059835 ,  0.00496693,  0.00286828, -0.01379409,\n",
       "        0.00434175], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_latent_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each user of the total 33901 users has been transformed into a 16 x 1 latent feature vector and each item of the total 126 has been transformed into a 16 x 1 latent feature vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK (Optional): Customize the RecommenderNet to potentially improve the model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-defined `RecommenderNet()` is a actually very basic neural network, you are encouraged to customize it to see if model prediction performance will be improved. Here are some directions:\n",
    "- Hyperparameter tuning, such as the embedding layer dimensions\n",
    "- Add more hidden layers\n",
    "- Try different activation functions such as `ReLu`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 76ms/step - loss: 0.4011 - root_mean_squared_error: 0.4163 - val_loss: 0.1683 - val_root_mean_squared_error: 0.4084\n",
      "Epoch 2/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 76ms/step - loss: 0.1678 - root_mean_squared_error: 0.4083 - val_loss: 0.1657 - val_root_mean_squared_error: 0.4068\n",
      "Epoch 3/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 76ms/step - loss: 0.1670 - root_mean_squared_error: 0.4084 - val_loss: 0.1656 - val_root_mean_squared_error: 0.4068\n",
      "Epoch 4/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 76ms/step - loss: 0.1665 - root_mean_squared_error: 0.4080 - val_loss: 0.1655 - val_root_mean_squared_error: 0.4068\n",
      "Epoch 5/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 78ms/step - loss: 0.1666 - root_mean_squared_error: 0.4082 - val_loss: 0.1654 - val_root_mean_squared_error: 0.4067\n",
      "Epoch 6/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 76ms/step - loss: 0.1671 - root_mean_squared_error: 0.4088 - val_loss: 0.1655 - val_root_mean_squared_error: 0.4068\n",
      "Epoch 7/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 75ms/step - loss: 0.1672 - root_mean_squared_error: 0.4090 - val_loss: 0.1655 - val_root_mean_squared_error: 0.4069\n",
      "Epoch 8/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 74ms/step - loss: 0.1666 - root_mean_squared_error: 0.4082 - val_loss: 0.1656 - val_root_mean_squared_error: 0.4069\n",
      "Epoch 9/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 75ms/step - loss: 0.1669 - root_mean_squared_error: 0.4085 - val_loss: 0.1658 - val_root_mean_squared_error: 0.4072\n",
      "Epoch 10/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 76ms/step - loss: 0.1672 - root_mean_squared_error: 0.4089 - val_loss: 0.1655 - val_root_mean_squared_error: 0.4068\n",
      "Epoch 11/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 76ms/step - loss: 0.1667 - root_mean_squared_error: 0.4083 - val_loss: 0.1655 - val_root_mean_squared_error: 0.4068\n",
      "Epoch 12/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 75ms/step - loss: 0.1668 - root_mean_squared_error: 0.4084 - val_loss: 0.1655 - val_root_mean_squared_error: 0.4068\n",
      "Epoch 13/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 76ms/step - loss: 0.1676 - root_mean_squared_error: 0.4094 - val_loss: 0.1654 - val_root_mean_squared_error: 0.4067\n",
      "Epoch 14/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 77ms/step - loss: 0.1666 - root_mean_squared_error: 0.4082 - val_loss: 0.1655 - val_root_mean_squared_error: 0.4068\n",
      "Epoch 15/15\n",
      "\u001b[1m2917/2917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 77ms/step - loss: 0.1672 - root_mean_squared_error: 0.4089 - val_loss: 0.1655 - val_root_mean_squared_error: 0.4068\n",
      "\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1656 - root_mean_squared_error: 0.4070\n",
      "Optimized Test RMSE: 0.4068\n"
     ]
    }
   ],
   "source": [
    "## Update RecommenderNet() class\n",
    "\n",
    "## compile and fit the updated model\n",
    "\n",
    "## evaluate the updated model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Optimized RecommenderNet Model with Regularization and Batch Normalization\n",
    "class OptimizedRecommenderNet(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_size=64):\n",
    "        super(OptimizedRecommenderNet, self).__init__()\n",
    "\n",
    "        # Embedding layers\n",
    "        self.user_embedding = Embedding(num_users, embedding_size, embeddings_regularizer=l2(0.001))\n",
    "        self.item_embedding = Embedding(num_items, embedding_size, embeddings_regularizer=l2(0.001))\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.hidden1 = Dense(128, activation=\"relu\", kernel_regularizer=l2(0.001))\n",
    "        self.hidden2 = Dense(64, activation=\"relu\", kernel_regularizer=l2(0.001))\n",
    "        self.hidden3 = Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001))\n",
    "\n",
    "        # Batch normalization\n",
    "        self.batch_norm1 = BatchNormalization()\n",
    "        self.batch_norm2 = BatchNormalization()\n",
    "        self.batch_norm3 = BatchNormalization()\n",
    "\n",
    "        # Dropout to prevent overfitting\n",
    "        self.dropout = Dropout(0.3)\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = Dense(1, activation=\"linear\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        item_vector = self.item_embedding(inputs[:, 1])\n",
    "\n",
    "        # Flatten and concatenate user and item embeddings\n",
    "        vector = tf.concat([user_vector, item_vector], axis=-1)\n",
    "        vector = Flatten()(vector)\n",
    "\n",
    "        # Fully connected layers with batch normalization and dropout\n",
    "        vector = self.hidden1(vector)\n",
    "        vector = self.batch_norm1(vector)\n",
    "        vector = self.dropout(vector)\n",
    "        \n",
    "        vector = self.hidden2(vector)\n",
    "        vector = self.batch_norm2(vector)\n",
    "        vector = self.dropout(vector)\n",
    "\n",
    "        vector = self.hidden3(vector)\n",
    "        vector = self.batch_norm3(vector)\n",
    "\n",
    "        return self.output_layer(vector)\n",
    "\n",
    "# Retrieve dataset dimensions\n",
    "num_users = x_train[:, 0].max() + 1\n",
    "num_items = x_train[:, 1].max() + 1\n",
    "\n",
    "# Initialize the model\n",
    "optimized_model = OptimizedRecommenderNet(num_users, num_items)\n",
    "\n",
    "# Compile the model with lower learning rate\n",
    "optimized_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "                        loss=\"mse\",\n",
    "                        metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "optimized_model.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test), batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "optimized_rmse = optimized_model.evaluate(x_test, y_test, verbose=1)[1]\n",
    "print(f\"Optimized Test RMSE: {optimized_rmse:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you have learned and practiced predicting course ratings using neural networks. With a predefined and trained neural network, we can extract or embed users and items into latent feature spaces and further predict the interaction between a user and an item with the latent feature vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Yan Luo](https://www.linkedin.com/in/yan-luo-96288783/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```toggle## Change Log\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```toggle|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "```\n",
    "```toggle|-|-|-|-|\n",
    "```\n",
    "```toggle|2021-10-25|1.0|Yan|Created the initial version|\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2021 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "b666e2b2e913b0897482548eb096a4e157b670ab86270b1b3a78e523a1f244d9"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
